"""
æ•°æ®æµè§ˆå™¨é¡µé¢
å±•ç¤ºæœ¬åœ° SQLite æ•°æ®åº“ä¸­çš„åŒæ­¥æ•°æ®ï¼Œæ”¯æŒå¤šç»´åº¦æŸ¥è¯¢ï¼š
1. å…¨å¸‚åœºå¿«ç…§ (æˆªé¢æ•°æ®)
2. ä¸ªè‚¡å†å² K çº¿ (æ—¶åºæ•°æ®)
"""
import streamlit as st
import pandas as pd
import sys
import os

sys.path.insert(0, '.')
from services import DataSyncService, StockService
from components.charts import render_chart, create_kline_chart

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ•°æ®æµè§ˆå™¨ - TS-Share", page_icon="ğŸ“", layout="wide")

# åˆå§‹åŒ–æœåŠ¡
sync_service = DataSyncService()
stock_service = StockService(use_cache=True)

# æ£€æŸ¥æ•°æ®åº“
if not os.path.exists(sync_service.db_path):
    st.warning("âš ï¸ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‰å¾€ã€Œç³»ç»Ÿè®¾ç½®ã€åŒæ­¥æ•°æ®ã€‚")
    if st.button("å‰å¾€åŒæ­¥"):
        st.switch_page("pages/3_settings.py")
    st.stop()

# ========== é¡µé¢æ ‡é¢˜ä¸æ¨¡å¼åˆ‡æ¢ ==========
st.title("ğŸ“ æ•°æ®æµè§ˆå™¨")

view_mode = st.radio(
    "é€‰æ‹©æµè§ˆæ¨¡å¼",
    options=["å…¨å¸‚åœºå¿«ç…§", "ä¸ªè‚¡å†å²æŸ¥è¯¢"],
    horizontal=True,
    help="ã€Œå…¨å¸‚åœºå¿«ç…§ã€æŸ¥çœ‹æŸä¸€æ—¥å…¨å¸‚åœºçš„è¡Œæƒ…æŒ‡æ ‡ï¼›ã€Œä¸ªè‚¡å†å²æŸ¥è¯¢ã€æŸ¥çœ‹å•åªè‚¡ç¥¨çš„æ—¶é—´åºåˆ—æ•°æ®å’Œ K çº¿å›¾ã€‚"
)

st.markdown("---")

# è·å–å·²åŒæ­¥çš„æ—¥æœŸåˆ—è¡¨
synced_dates = sync_service.get_synced_dates()
if not synced_dates:
    st.warning("ğŸ“­ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆåŒæ­¥æ•°æ®ã€‚")
    st.stop()

# ==================== æ¨¡å¼ 1ï¼šå…¨å¸‚åœºå¿«ç…§ ====================
if view_mode == "å…¨å¸‚åœºå¿«ç…§":
    # ä¾§è¾¹æ ç­›é€‰å™¨
    st.sidebar.header("ğŸ” å…¨å¸‚åœºç­›é€‰")
    
    selected_date = st.sidebar.selectbox("é€‰æ‹©æ—¥æœŸ", options=reversed(synced_dates), index=0)
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("æŒ‡æ ‡ç­›é€‰")
    
    min_pct_chg = st.sidebar.number_input("æœ€å°æ¶¨è·Œå¹… (%)", value=-10.0, step=1.0)
    max_pct_chg = st.sidebar.number_input("æœ€å¤§æ¶¨è·Œå¹… (%)", value=20.0, step=1.0)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        min_pe = st.sidebar.number_input("æœ€å° PE", value=0.0, step=1.0)
    with col2:
        max_pe = st.sidebar.number_input("æœ€å¤§ PE", value=500.0, step=1.0)
    
    max_market_cap = st.sidebar.number_input("æœ€å¤§æµé€šå¸‚å€¼ (äº¿)", value=5000.0, step=10.0)
    search_code = st.sidebar.text_input("æœç´¢è‚¡ç¥¨ä»£ç  (å¦‚ 000001)", help="ç•™ç©ºæ˜¾ç¤ºå…¨åœº")

    # æ„å»ºæŸ¥è¯¢é€»è¾‘
    def fetch_market_data():
        conditions = ["æ—¥æœŸ = ?"]
        params = [selected_date]
        
        if search_code:
            conditions.append("ä»£ç  LIKE ?")
            params.append(f"%{search_code}%")
        else:
            conditions.append("æ¶¨è·Œå¹… >= ?")
            params.append(min_pct_chg)
            conditions.append("æ¶¨è·Œå¹… <= ?")
            params.append(max_pct_chg)
            
            if min_pe > 0:
                conditions.append("PE >= ?")
                params.append(min_pe)
            if max_pe < 500:
                conditions.append("PE <= ?")
                params.append(max_pe)
                
            if max_market_cap < 5000:
                conditions.append("æµé€šå¸‚å€¼ <= ?")
                params.append(max_market_cap * 10000) # äº¿ -> ä¸‡
                
        where_clause = " AND ".join(conditions)
        sql = f"SELECT * FROM daily_data WHERE {where_clause} ORDER BY æ¶¨è·Œå¹… DESC"
        return sync_service.query(sql, tuple(params))

    # æ‰§è¡ŒæŸ¥è¯¢
    with st.spinner("æŸ¥è¯¢ä¸­..."):
        df = fetch_market_data()

    if df.empty:
        st.info(f"ğŸ§ æœªæ‰¾åˆ°åŒ¹é… '{selected_date}' çš„æ•°æ®ã€‚")
    else:
        st.subheader(f"ğŸ“Š å…¨å¸‚åœºå¿«ç…§ - {selected_date}")
        st.markdown(f"**å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•**")
        
        # åˆ†é¡µè®¾ç½®
        items_per_page = 50
        total_pages = (len(df) - 1) // items_per_page + 1
        page_num = st.number_input(f"é¡µç  (1/{total_pages})", min_value=1, max_value=total_pages, value=1) if total_pages > 1 else 1
            
        start_idx = (page_num - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_df = df.iloc[start_idx:end_idx].copy()
        
        # æŒ‡æ ‡ç¾åŒ–
        if 'æµé€šå¸‚å€¼' in page_df.columns:
            page_df['æµé€šå¸‚å€¼(äº¿)'] = (page_df['æµé€šå¸‚å€¼'] / 10000).round(2)
            
        display_cols = ['æ—¥æœŸ', 'ä»£ç ', 'æ”¶ç›˜', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'PE', 'PE_TTM', 'PB', 'æµé€šå¸‚å€¼(äº¿)', 'æˆäº¤é¢']
        available_cols = [c for c in display_cols if c in page_df.columns]
        
        st.dataframe(
            page_df[available_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "æ¶¨è·Œå¹…": st.column_config.NumberColumn("æ¶¨è·Œå¹…", format="%.2f%%"),
                "æ¢æ‰‹ç‡": st.column_config.NumberColumn("æ¢æ‰‹ç‡", format="%.2f%%"),
                "æµé€šå¸‚å€¼(äº¿)": st.column_config.NumberColumn("æµé€šå¸‚å€¼(äº¿)", format="%.2f äº¿"),
            }
        )
        
        # å¯¼å‡º
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(label="ğŸ“¥ å¯¼å‡ºç­›é€‰ç»“æœ CSV", data=csv, file_name=f"market_{selected_date}.csv", mime="text/csv")

# ==================== æ¨¡å¼ 2ï¼šä¸ªè‚¡å†å²æŸ¥è¯¢ ====================
else:
    st.sidebar.header("ğŸ” ä¸ªè‚¡å†å²ç­›é€‰")
    
    # è‚¡ç¥¨ä»£ç è¾“å…¥
    search_code = st.sidebar.text_input("è‚¡ç¥¨ä»£ç ", value="000001", max_chars=6)
    
    # æœ€è¿‘ N å¤©
    history_days = st.sidebar.slider("æŸ¥çœ‹å¤©æ•°", min_value=5, max_value=365, value=60)
    
    # æŸ¥è¯¢
    with st.spinner(f"æ­£åœ¨è·å– {search_code} çš„å†å²æ•°æ®..."):
        df_history = stock_service.get_history(search_code, days=history_days)
        
    if df_history is None or df_history.empty:
        st.warning(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä»£ç ä¸º '{search_code}' çš„å†å²æ•°æ®ã€‚")
        st.info("ğŸ’¡ è¯·ç¡®ä¿å·²åœ¨è®¾ç½®ä¸­åŒæ­¥äº†è¯¥è‚¡ç¥¨æ‰€å±çš„æ—¶é—´èŒƒå›´ã€‚")
    else:
        st.subheader(f"ğŸ“ˆ {search_code} å†å²è¡Œæƒ…ä¸ K çº¿å›¾")
        
        # ç»Ÿè®¡æŒ‡æ ‡
        latest = df_history.iloc[-1]
        cols = st.columns(4)
        cols[0].metric("æœ€æ–°æ”¶ç›˜", f"{latest['æ”¶ç›˜']:.2f}")
        cols[1].metric("æ¶¨è·Œå¹…", f"{latest['æ¶¨è·Œå¹…']:.2f}%")
        cols[2].metric("æœ€æ–°æ¢æ‰‹", f"{latest['æ¢æ‰‹ç‡']:.2f}%")
        cols[3].metric("PE(åŠ¨)", f"{latest['PE']:.2f}" if pd.notnull(latest['PE']) else "N/A")
        
        st.markdown("---")
        
        # K çº¿å›¾
        with st.container():
            kline_chart = create_kline_chart(df_history, title=f"{search_code} è¿‘ {len(df_history)} äº¤æ˜“æ—¥ K çº¿")
            render_chart(kline_chart, height=550)
            
        st.markdown("---")
        
        # å†å²æ•°æ®è¡¨æ ¼
        st.subheader("ğŸ“‹ å†å²æ•°æ®æ˜ç»†")
        page_df = df_history.sort_values('æ—¥æœŸ', ascending=False).copy()
        
        if 'æµé€šå¸‚å€¼' in page_df.columns:
            page_df['æµé€šå¸‚å€¼(äº¿)'] = (page_df['æµé€šå¸‚å€¼'] / 10000).round(2)
            
        display_cols = ['æ—¥æœŸ', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'PE', 'æµé€šå¸‚å€¼(äº¿)', 'æˆäº¤é¢']
        available_cols = [c for c in display_cols if c in page_df.columns]
        
        st.dataframe(
            page_df[available_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "æ¶¨è·Œå¹…": st.column_config.NumberColumn("æ¶¨è·Œå¹…", format="%.2f%%"),
                "æ¢æ‰‹ç‡": st.column_config.NumberColumn("æ¢æ‰‹ç‡", format="%.2f%%"),
                "æµé€šå¸‚å€¼(äº¿)": st.column_config.NumberColumn("æµé€šå¸‚å€¼(äº¿)", format="%.2f äº¿"),
            }
        )
        
        # å¯¼å‡º
        csv = df_history.to_csv(index=False).encode('utf-8-sig')
        st.download_button(label=f"ğŸ“¥ å¯¼å‡º {search_code} å†å²æ•°æ® CSV", data=csv, file_name=f"stock_{search_code}_history.csv", mime="text/csv")

# ========== åº•éƒ¨ä¿¡æ¯ ==========
st.markdown("---")
st.caption(f"ğŸ’¡ æ•°æ®æº: Tushare Pro | æ•°æ®åº“æ–‡ä»¶: {sync_service.db_path}")
