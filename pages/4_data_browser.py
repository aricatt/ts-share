"""
æ•°æ®æµè§ˆå™¨é¡µé¢
å±•ç¤ºæœ¬åœ° SQLite æ•°æ®åº“ä¸­çš„åŒæ­¥æ•°æ®ï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰
"""
import streamlit as st
import pandas as pd
import sys
import os

sys.path.insert(0, '.')
from services import DataSyncService

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ•°æ®æµè§ˆå™¨ - TS-Share", page_icon="ğŸ“", layout="wide")

st.title("ğŸ“ æ•°æ®æµè§ˆå™¨")
st.markdown("æµè§ˆæœ¬åœ° SQLite æ•°æ®åº“ä¸­çš„å…¨å¸‚åœºåŒæ­¥æ•°æ®")

# åˆå§‹åŒ–åŒæ­¥æœåŠ¡
sync_service = DataSyncService()

# æ£€æŸ¥æ•°æ®åº“
if not os.path.exists(sync_service.db_path):
    st.warning("âš ï¸ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‰å¾€ã€Œç³»ç»Ÿè®¾ç½®ã€åŒæ­¥æ•°æ®ã€‚")
    if st.button("å‰å¾€åŒæ­¥"):
        st.switch_page("pages/3_settings.py")
    st.stop()

# ========== ä¾§è¾¹æ ç­›é€‰å™¨ ==========
st.sidebar.header("ğŸ” æ•°æ®ç­›é€‰")

# è·å–å·²åŒæ­¥çš„æ—¥æœŸ
synced_dates = sync_service.get_synced_dates()
if not synced_dates:
    st.warning("ğŸ“­ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆåŒæ­¥æ•°æ®ã€‚")
    st.stop()

# é»˜è®¤é€‰æ‹©æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥
latest_date = synced_dates[-1]
selected_date = st.sidebar.selectbox("é€‰æ‹©æ—¥æœŸ", options=reversed(synced_dates), index=0)

# å…¶ä»–ç­›é€‰æ¡ä»¶
st.sidebar.markdown("---")
st.sidebar.subheader("æŒ‡æ ‡ç­›é€‰")

min_pct_chg = st.sidebar.number_input("æœ€å°æ¶¨è·Œå¹… (%)", value=-10.0, step=1.0)
max_pct_chg = st.sidebar.number_input("æœ€å¤§æ¶¨è·Œå¹… (%)", value=20.0, step=1.0)

col1, col2 = st.sidebar.columns(2)
with col1:
    min_pe = st.sidebar.number_input("æœ€å° PE", value=0.0, step=1.0)
with col2:
    max_pe = st.sidebar.number_input("æœ€å¤§ PE", value=500.0, step=1.0)

max_market_cap = st.sidebar.number_input("æœ€å¤§æµé€šå¸‚å€¼ (äº¿)", value=5000.0, step=10.0)

# è‚¡ç¥¨ä»£ç æœç´¢
search_code = st.sidebar.text_input("æœç´¢è‚¡ç¥¨ä»£ç  (å¦‚ 000001)", help="ç•™ç©ºæ˜¾ç¤ºå…¨åœº")

# ========== æ•°æ®æŸ¥è¯¢ ==========

# æ„å»ºæŸ¥è¯¢é€»è¾‘
def fetch_filtered_data():
    conditions = ["æ—¥æœŸ = ?"]
    params = [selected_date]
    
    if search_code:
        conditions.append("ä»£ç  LIKE ?")
        params.append(f"%{search_code}%")
    else:
        conditions.append("æ¶¨è·Œå¹… >= ?")
        params.append(min_pct_chg)
        conditions.append("æ¶¨è·Œå¹… <= ?")
        params.append(max_pct_chg)
        
        if min_pe > 0:
            conditions.append("PE >= ?")
            params.append(min_pe)
        if max_pe < 500:
            conditions.append("PE <= ?")
            params.append(max_pe)
            
        if max_market_cap < 5000:
            conditions.append("æµé€šå¸‚å€¼ <= ?")
            params.append(max_market_cap * 10000) # äº¿ -> ä¸‡
            
    where_clause = " AND ".join(conditions)
    sql = f"SELECT * FROM daily_data WHERE {where_clause} ORDER BY æ¶¨è·Œå¹… DESC"
    
    return sync_service.query(sql, tuple(params))

# æ‰§è¡ŒæŸ¥è¯¢
with st.spinner("æŸ¥è¯¢ä¸­..."):
    df = fetch_filtered_data()

# ========== æ•°æ®å±•ç¤º ==========

if df.empty:
    st.info(f"ğŸ§ æœªæ‰¾åˆ°åŒ¹é… '{selected_date}' çš„æ•°æ®ï¼Œè¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶ã€‚")
else:
    # ç»Ÿè®¡ä¿¡æ¯
    st.markdown(f"**å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•**")
    
    # åˆ†é¡µè®¾ç½®
    items_per_page = 50
    total_pages = (len(df) - 1) // items_per_page + 1
    
    if total_pages > 1:
        page_num = st.number_input(f"é¡µç  (1/{total_pages})", min_value=1, max_value=total_pages, value=1)
    else:
        page_num = 1
        
    start_idx = (page_num - 1) * items_per_page
    end_idx = start_idx + items_per_page
    
    page_df = df.iloc[start_idx:end_idx].copy()
    
    # æŒ‡æ ‡ç¾åŒ–
    if 'æµé€šå¸‚å€¼' in page_df.columns:
        page_df['æµé€šå¸‚å€¼(äº¿)'] = (page_df['æµé€šå¸‚å€¼'] / 10000).round(2)
    if 'æ€»å¸‚å€¼' in page_df.columns:
        page_df['æ€»å¸‚å€¼(äº¿)'] = (page_df['æ€»å¸‚å€¼'] / 10000).round(2)
        
    # é‡æ–°æ’åˆ—åˆ—ï¼Œæ–¹ä¾¿æŸ¥çœ‹
    display_cols = ['æ—¥æœŸ', 'ä»£ç ', 'æ”¶ç›˜', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'PE', 'PE_TTM', 'PB', 'æµé€šå¸‚å€¼(äº¿)', 'æˆäº¤é¢']
    available_cols = [c for c in display_cols if c in page_df.columns]
    
    # é‡ç‚¹æ˜¾ç¤º
    st.dataframe(
        page_df[available_cols],
        use_container_width=True,
        hide_index=True,
        column_config={
            "æ—¥æœŸ": st.column_config.TextColumn("æ—¥æœŸ"),
            "ä»£ç ": st.column_config.TextColumn("ä»£ç "),
            "æ¶¨è·Œå¹…": st.column_config.NumberColumn("æ¶¨è·Œå¹…", format="%.2f%%"),
            "æ¢æ‰‹ç‡": st.column_config.NumberColumn("æ¢æ‰‹ç‡", format="%.2f%%"),
            "æµé€šå¸‚å€¼(äº¿)": st.column_config.NumberColumn("æµé€šå¸‚å€¼(äº¿)", format="%.2f äº¿"),
            "æˆäº¤é¢": st.column_config.NumberColumn("æˆäº¤é¢", format="%.0f")
        }
    )
    
    # å¯¼å‡ºåŠŸèƒ½
    st.markdown("---")
    csv = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ å¯¼å‡ºå½“å‰ç­›é€‰ç»“æœä¸º CSV",
        data=csv,
        file_name=f"stock_data_{selected_date}.csv",
        mime="text/csv",
    )

# ========== åº•éƒ¨ä¿¡æ¯ ==========
st.markdown("---")
st.caption(f"ğŸ’¡ æ•°æ®æº: Tushare Pro | æ•°æ®åº“æ–‡ä»¶: {sync_service.db_path}")
