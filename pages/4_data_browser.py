"""
æ•°æ®æµè§ˆå™¨é¡µé¢
å±•ç¤ºæœ¬åœ° SQLite æ•°æ®åº“ä¸­çš„åŒæ­¥æ•°æ®ï¼Œæ”¯æŒå¤šç»´åº¦æŸ¥è¯¢ï¼š
1. å…¨å¸‚åœºå¿«ç…§ (æˆªé¢æ•°æ®)
2. ä¸ªè‚¡å†å² K çº¿ (æ—¶åºæ•°æ®)
"""
import streamlit as st
import pandas as pd
import sys
import os

sys.path.insert(0, '.')
from services import DataSyncService, StockService
from components.charts import render_chart, create_kline_chart
from components.stock_details import show_stock_details

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ•°æ®æµè§ˆå™¨ - TS-Share", page_icon="ğŸ“", layout="wide")

# åˆå§‹åŒ–æœåŠ¡
sync_service = DataSyncService()
stock_service = StockService(use_cache=True)

# æ£€æŸ¥æ•°æ®åº“
if not os.path.exists(sync_service.db_path):
    st.warning("âš ï¸ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‰å¾€ã€Œç³»ç»Ÿè®¾ç½®ã€åŒæ­¥æ•°æ®ã€‚")
    if st.button("å‰å¾€åŒæ­¥"):
        st.switch_page("pages/3_settings.py")
    st.stop()

# ========== é¡µé¢æ ‡é¢˜ä¸æ¨¡å¼åˆ‡æ¢ ==========
st.title("ğŸ“ æ•°æ®æµè§ˆå™¨")

view_mode = st.radio(
    "é€‰æ‹©æµè§ˆæ¨¡å¼",
    options=["å…¨å¸‚åœºå¿«ç…§", "ä¸ªè‚¡å†å²æŸ¥è¯¢"],
    horizontal=True,
    help="ã€Œå…¨å¸‚åœºå¿«ç…§ã€æŸ¥çœ‹æŸä¸€æ—¥å…¨å¸‚åœºçš„è¡Œæƒ…æŒ‡æ ‡ï¼›ã€Œä¸ªè‚¡å†å²æŸ¥è¯¢ã€æŸ¥çœ‹å•åªè‚¡ç¥¨çš„æ—¶é—´åºåˆ—æ•°æ®å’Œ K çº¿å›¾ã€‚"
)

st.markdown("---")

# è·å–å·²åŒæ­¥çš„æ—¥æœŸåˆ—è¡¨
synced_dates = sync_service.get_synced_dates()
if not synced_dates:
    st.warning("ğŸ“­ æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆåŒæ­¥æ•°æ®ã€‚")
    st.stop()

# ==================== æ¨¡å¼ 1ï¼šå…¨å¸‚åœºå¿«ç…§ ====================
if view_mode == "å…¨å¸‚åœºå¿«ç…§":
    # ä¾§è¾¹æ ç­›é€‰å™¨
    st.sidebar.header("ğŸ” å…¨å¸‚åœºç­›é€‰")
    
    selected_date = st.sidebar.selectbox("é€‰æ‹©æ—¥æœŸ", options=reversed(synced_dates), index=0)
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("æŒ‡æ ‡ç­›é€‰")
    
    min_pct_chg = st.sidebar.number_input("æœ€å°æ¶¨è·Œå¹… (%)", value=-10.0, step=1.0)
    max_pct_chg = st.sidebar.number_input("æœ€å¤§æ¶¨è·Œå¹… (%)", value=20.0, step=1.0)
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        min_pe = st.sidebar.number_input("æœ€å° PE", value=0.0, step=1.0)
    with col2:
        max_pe = st.sidebar.number_input("æœ€å¤§ PE", value=500.0, step=1.0)
    
    max_market_cap = st.sidebar.number_input("æœ€å¤§æµé€šå¸‚å€¼ (äº¿)", value=5000.0, step=10.0)
    search_code = st.sidebar.text_input("æœç´¢è‚¡ç¥¨ä»£ç  (å¦‚ 000001)", help="ç•™ç©ºæ˜¾ç¤ºå…¨åœº")

    # æ„å»ºæŸ¥è¯¢é€»è¾‘
    def fetch_market_data():
        conditions = ["æ—¥æœŸ = ?"]
        params = [selected_date]
        
        if search_code:
            conditions.append("ä»£ç  LIKE ?")
            params.append(f"%{search_code}%")
        else:
            conditions.append("æ¶¨è·Œå¹… >= ?")
            params.append(min_pct_chg)
            conditions.append("æ¶¨è·Œå¹… <= ?")
            params.append(max_pct_chg)
            
            if min_pe > 0:
                conditions.append("PE >= ?")
                params.append(min_pe)
            if max_pe < 500:
                conditions.append("PE <= ?")
                params.append(max_pe)
                
            if max_market_cap < 5000:
                conditions.append("æµé€šå¸‚å€¼ <= ?")
                params.append(max_market_cap * 10000) # äº¿ -> ä¸‡
                
        where_clause = " AND ".join(conditions)
        sql = f"""
            SELECT d.*, b.åç§° 
            FROM daily_data d
            LEFT JOIN stock_basic b ON d.ä»£ç  = b.ä»£ç 
            WHERE {where_clause.replace('æ—¥æœŸ', 'd.æ—¥æœŸ').replace('ä»£ç ', 'd.ä»£ç ').replace('æ¶¨è·Œå¹…', 'd.æ¶¨è·Œå¹…').replace('PE', 'd.PE').replace('æµé€šå¸‚å€¼', 'd.æµé€šå¸‚å€¼')}
            ORDER BY d.æ¶¨è·Œå¹… DESC
        """
        return sync_service.query(sql, tuple(params))

    # æ‰§è¡ŒæŸ¥è¯¢
    with st.spinner("æŸ¥è¯¢ä¸­..."):
        df = fetch_market_data()
        if not df.empty:
            df = df.loc[:, ~df.columns.duplicated()]

    if df.empty:
        st.info(f"ğŸ§ æœªæ‰¾åˆ°åŒ¹é… '{selected_date}' çš„æ•°æ®ã€‚")
    else:
        st.subheader(f"ğŸ“Š å…¨å¸‚åœºå¿«ç…§ - {selected_date}")
        st.markdown(f"**å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•**")
        
        # åˆ†é¡µè®¾ç½®
        items_per_page = 50
        total_pages = (len(df) - 1) // items_per_page + 1
        page_num = st.number_input(f"é¡µç  (1/{total_pages})", min_value=1, max_value=total_pages, value=1) if total_pages > 1 else 1
            
        start_idx = (page_num - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_df = df.iloc[start_idx:end_idx].copy()
        
        # æŒ‡æ ‡ç¾åŒ–
        if 'æµé€šå¸‚å€¼' in page_df.columns:
            page_df['æµé€šå¸‚å€¼(äº¿)'] = (page_df['æµé€šå¸‚å€¼'] / 10000).round(2)
            
        display_cols = ['æ—¥æœŸ', 'ä»£ç ', 'åç§°', 'æ”¶ç›˜', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'PE', 'PE_TTM', 'PB', 'æµé€šå¸‚å€¼(äº¿)', 'æˆäº¤é¢']
        available_cols = [c for c in display_cols if c in page_df.columns]
        
        st.dataframe(
            page_df[available_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "ä»£ç ": st.column_config.TextColumn("ä»£ç "),
                "åç§°": st.column_config.TextColumn("åç§°"),
                "æ¶¨è·Œå¹…": st.column_config.NumberColumn("æ¶¨è·Œå¹…", format="%.2f%%"),
                "æ¢æ‰‹ç‡": st.column_config.NumberColumn("æ¢æ‰‹ç‡", format="%.2f%%"),
                "æµé€šå¸‚å€¼(äº¿)": st.column_config.NumberColumn("æµé€šå¸‚å€¼(äº¿)", format="%.2f äº¿"),
            }
        )
        
        # å¯¼å‡º
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(label="ğŸ“¥ å¯¼å‡ºç­›é€‰ç»“æœ CSV", data=csv, file_name=f"market_{selected_date}.csv", mime="text/csv")

# ==================== æ¨¡å¼ 2ï¼šä¸ªè‚¡å†å²æŸ¥è¯¢ ====================
else:
    st.sidebar.header("ğŸ” ä¸ªè‚¡å†å²ç­›é€‰")
    
    # è‚¡ç¥¨æœå¯»
    search_keyword = st.sidebar.text_input("æœç´¢è‚¡ç¥¨ (ä»£ç æˆ–åç§°)", value="000001", key="stock_search_input", help="æ”¯æŒä»£ç æ¨¡ç³Šæˆ–åç§°æ¨¡ç³ŠæŸ¥è¯¢ï¼Œå¦‚ï¼š'ä¸‡ç§‘' æˆ– '000002'")
    
    # æ‰§è¡Œæœç´¢
    search_results = stock_service.search_stocks(search_keyword, limit=20)
    
    if search_results.empty:
        st.sidebar.error("ğŸš« æœªæœåˆ°ç›¸å…³è‚¡ç¥¨")
        st.stop()
        
    # æ„é€ æ›´ç¨³å®šçš„é€‰é¡¹åˆ—è¡¨
    # ä½¿ç”¨ å­—å…¸ æ¥å­˜å‚¨ ä»£ç  -> æ˜¾ç¤ºæ–‡å­— çš„æ˜ å°„ï¼Œæ–¹ä¾¿åæŸ¥
    stock_options = {}
    for _, row in search_results.iterrows():
        label = f"{row['ä»£ç ']} - {row['åç§°']}"
        if pd.notnull(row['è¡Œä¸š']):
            label += f" ({row['è¡Œä¸š']})"
        stock_options[row['ä»£ç ']] = label
    
    # è·å–é€‰é¡¹åˆ—è¡¨
    labels = list(stock_options.values())
    
    # æŸ¥æ‰¾å½“å‰é€‰ä¸­é¡¹åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
    current_idx = 0
    if 'last_selected_code' in st.session_state:
        target_code = st.session_state['last_selected_code']
        # å¦‚æœå½“å‰æœç´¢ç»“æœé‡ŒåŒ…å«ä¸Šæ¬¡é€‰ä¸­çš„ä»£ç ï¼Œåˆ™ä¿æŒé€‰ä¸­
        for i, code in enumerate(stock_options.keys()):
            if code == target_code:
                current_idx = i
                break
    
    selected_label = st.sidebar.selectbox(
        "é€‰æ‹©åŒ¹é…ç»“æœ", 
        options=labels, 
        index=current_idx,
        key="stock_search_select"
    )
    
    # è§£æé€‰ä¸­çš„ä»£ç å¹¶å­˜å…¥ state
    search_code = selected_label.split(" - ")[0]
    st.session_state['last_selected_code'] = search_code
    selected_option = selected_label # ç”¨äºåç»­å±•ç¤º
    
    # æŸ¥çœ‹å¤©æ•°ï¼ˆé»˜è®¤æ˜¾ç¤º1å¹´çº¦250ä¸ªäº¤æ˜“æ—¥ï¼Œæœ€å¤§æ”¯æŒçº¦3å¹´ï¼‰
    history_days = st.sidebar.slider("æŸ¥çœ‹å¤©æ•° (äº¤æ˜“æ—¥)", min_value=5, max_value=750, value=250)
    
    # å¤æƒé€‰é¡¹
    adj_type = st.sidebar.selectbox("å¤æƒæ–¹å¼", options=["å‰å¤æƒ", "æœªå¤æƒ"])
    
    # æŸ¥è¯¢
    with st.spinner(f"æ­£åœ¨è·å– {selected_option} çš„å†å²æ•°æ®..."):
        df_history = stock_service.get_history(search_code, days=history_days)
        # ç§»é™¤é‡å¤åˆ—å
        if df_history is not None and not df_history.empty:
            df_history = df_history.loc[:, ~df_history.columns.duplicated()]
        
    if df_history is None or df_history.empty:
        st.warning(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä»£ç ä¸º '{search_code}' çš„å†å²æ•°æ®ã€‚")
        st.info("ğŸ’¡ è¯·ç¡®ä¿å·²åœ¨è®¾ç½®ä¸­åŒæ­¥äº†è¯¥è‚¡ç¥¨æ‰€å±çš„æ—¶é—´èŒƒå›´ã€‚")
    else:
        # å‡†å¤‡å›¾è¡¨æ•°æ®
        df_plot = df_history.copy()
        if adj_type == "å‰å¤æƒ" and "qfq_æ”¶ç›˜" in df_plot.columns and df_plot["qfq_æ”¶ç›˜"].notnull().any():
            df_plot["å¼€ç›˜"] = df_plot["qfq_å¼€ç›˜"]
            df_plot["æœ€é«˜"] = df_plot["qfq_æœ€é«˜"]
            df_plot["æœ€ä½"] = df_plot["qfq_æœ€ä½"]
            df_plot["æ”¶ç›˜"] = df_plot["qfq_æ”¶ç›˜"]
            chart_title = f"{search_code} {adj_type} K çº¿"
        else:
            chart_title = f"{search_code} æœªå¤æƒ K çº¿"

        st.subheader(f"ğŸ“ˆ {search_code} å†å²è¡Œæƒ…ä¸ K çº¿å›¾ ({adj_type})")
        
        # ç»Ÿè®¡æŒ‡æ ‡
        latest = df_history.iloc[-1]
        cols = st.columns(5)
        # å¢åŠ  AI è¯Šæ–­æŒ‰é’®
        if cols[0].button("ğŸ”¬ æ·±åº¦ AI è¯Šæ–­", key=f"ai_diag_{search_code}", use_container_width=True):
            st.session_state.pending_details = (search_code, stock_service.get_stock_name(search_code))

        cols[1].metric("æœ€æ–°æ”¶ç›˜", f"{latest['æ”¶ç›˜']:.2f}")
        cols[2].metric("æ¶¨è·Œå¹…", f"{latest['æ¶¨è·Œå¹…']:.2f}%")
        cols[3].metric("æœ€æ–°æˆäº¤", f"{int(latest['æˆäº¤é‡']):,}")
        cols[4].metric("VMA5", f"{int(latest['vma5']):,}" if 'vma5' in latest and pd.notnull(latest['vma5']) else "N/A")
        
        st.markdown("---")
        
        # K çº¿å›¾
        with st.container():
            kline_chart = create_kline_chart(df_plot, title=chart_title)
            render_chart(kline_chart, height=650)
            
        st.markdown("---")
        
        # å†å²æ•°æ®è¡¨æ ¼
        st.subheader("ğŸ“‹ å†å²æ•°æ®æ˜ç»†")
        page_df = df_history.sort_values('æ—¥æœŸ', ascending=False).copy()
        
        if 'æµé€šå¸‚å€¼' in page_df.columns:
            page_df['æµé€šå¸‚å€¼(äº¿)'] = (page_df['æµé€šå¸‚å€¼'] / 10000).round(2)
            
        display_cols = ['æ—¥æœŸ', 'ä»£ç ', 'åç§°', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'PE', 'æµé€šå¸‚å€¼(äº¿)', 'æˆäº¤é¢']
        available_cols = [c for c in display_cols if c in page_df.columns]
        
        st.dataframe(
            page_df[available_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "ä»£ç ": st.column_config.TextColumn("ä»£ç "),
                "åç§°": st.column_config.TextColumn("åç§°"),
                "æ¶¨è·Œå¹…": st.column_config.NumberColumn("æ¶¨è·Œå¹…", format="%.2f%%"),
                "æ¢æ‰‹ç‡": st.column_config.NumberColumn("æ¢æ‰‹ç‡", format="%.2f%%"),
                "æµé€šå¸‚å€¼(äº¿)": st.column_config.NumberColumn("æµé€šå¸‚å€¼(äº¿)", format="%.2f äº¿"),
            }
        )
        
        # å¯¼å‡º
        csv = df_history.to_csv(index=False).encode('utf-8-sig')
        st.download_button(label=f"ğŸ“¥ å¯¼å‡º {search_code} å†å²æ•°æ® CSV", data=csv, file_name=f"stock_{search_code}_history.csv", mime="text/csv")

# ========== åº•éƒ¨ä¿¡æ¯ ==========
# ### é¡µé¢åº•éƒ¨ï¼šå¤„ç†å¾…è§¦å‘çš„å¼¹çª— ###
if 'pending_details' not in st.session_state:
    st.session_state.pending_details = None

if st.session_state.pending_details:
    code, name = st.session_state.pending_details
    st.session_state.pending_details = None # æ¸…é™¤ä¿¡å·
    show_stock_details(code, name, stock_service)

st.markdown("---")
st.caption(f"ğŸ’¡ æ•°æ®æº: Tushare Pro | æ•°æ®åº“æ–‡ä»¶: {sync_service.db_path}")
