"""
æœ¬åœ°æ•°æ®åŒæ­¥æœåŠ¡
åŸºäºŽ Tushare Pro + SQLite å­˜å‚¨

ä¼˜åŠ¿ï¼š
- å•æ–‡ä»¶å­˜å‚¨ï¼Œä¾¿äºŽå¤‡ä»½è¿ç§»
- æ”¯æŒ SQL æŸ¥è¯¢ï¼Œç­›é€‰çµæ´»
- æ‰¹é‡å†™å…¥é«˜æ•ˆ
- Python å†…ç½®æ”¯æŒ
"""
import os
import json
import sqlite3
import tushare as ts
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict
import time
import threading
import fcntl

from config import TUSHARE_TOKEN


# å…¨å±€çº¿ç¨‹é”
_sync_lock = threading.Lock()


class DataSyncService:
    """
    æœ¬åœ°æ•°æ®åŒæ­¥æœåŠ¡ï¼ˆSQLite å­˜å‚¨ç‰ˆï¼‰
    
    å­˜å‚¨ç»“æž„ï¼š
        data/
        â”œâ”€â”€ stocks.db          # SQLite æ•°æ®åº“
        â””â”€â”€ metadata.json      # åŒæ­¥å…ƒæ•°æ®
    
    æ•°æ®è¡¨ï¼š
        daily_data: æ—¥æœŸ, ä»£ç , å¼€ç›˜, æœ€é«˜, æœ€ä½Ž, æ”¶ç›˜, æ¶¨è·Œå¹…, æˆäº¤é‡, æ¢æ‰‹çŽ‡, PE, PB, å¸‚å€¼...
    """
    
    _is_syncing = False
    _sync_start_time = None
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.db_path = os.path.join(data_dir, "stocks.db")
        self.metadata_path = os.path.join(data_dir, "metadata.json")
        self.lock_file_path = os.path.join(data_dir, ".sync.lock")
        self._stop_requested = False
        self._lock_fd = None
        
        # åˆå§‹åŒ– Tushare Pro
        if not TUSHARE_TOKEN:
            raise ValueError("Tushare Token æœªé…ç½®")
        ts.set_token(TUSHARE_TOKEN)
        self.pro = ts.pro_api()
        
        # åˆ›å»ºç›®å½•å’Œæ•°æ®åº“
        os.makedirs(data_dir, exist_ok=True)
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æž„"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS daily_data (
                    æ—¥æœŸ TEXT NOT NULL,
                    ä»£ç  TEXT NOT NULL,
                    å¼€ç›˜ REAL,
                    æœ€é«˜ REAL,
                    æœ€ä½Ž REAL,
                    æ”¶ç›˜ REAL,
                    æ˜¨æ”¶ REAL,
                    æ¶¨è·Œé¢ REAL,
                    æ¶¨è·Œå¹… REAL,
                    æˆäº¤é‡ REAL,
                    æˆäº¤é¢ REAL,
                    æ¢æ‰‹çŽ‡ REAL,
                    é‡æ¯” REAL,
                    PE REAL,
                    PE_TTM REAL,
                    PB REAL,
                    æ€»å¸‚å€¼ REAL,
                    æµé€šå¸‚å€¼ REAL,
                    æ€»è‚¡æœ¬ REAL,
                    æµé€šè‚¡æœ¬ REAL,
                    PRIMARY KEY (æ—¥æœŸ, ä»£ç )
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•åŠ é€ŸæŸ¥è¯¢
            conn.execute('CREATE INDEX IF NOT EXISTS idx_code ON daily_data(ä»£ç )')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_date ON daily_data(æ—¥æœŸ)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_pct_chg ON daily_data(æ¶¨è·Œå¹…)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_pe ON daily_data(PE)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_market_cap ON daily_data(æµé€šå¸‚å€¼)')
            
            conn.commit()
    
    # ==================== é”æœºåˆ¶ ====================
    
    def _acquire_lock(self) -> bool:
        if not _sync_lock.acquire(blocking=False):
            return False
        try:
            self._lock_fd = open(self.lock_file_path, 'w')
            fcntl.flock(self._lock_fd.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
            lock_info = {"pid": os.getpid(), "start_time": datetime.now().isoformat()}
            self._lock_fd.write(json.dumps(lock_info))
            self._lock_fd.flush()
            DataSyncService._is_syncing = True
            DataSyncService._sync_start_time = datetime.now()
            return True
        except (IOError, OSError):
            _sync_lock.release()
            return False
    
    def _release_lock(self):
        DataSyncService._is_syncing = False
        DataSyncService._sync_start_time = None
        if self._lock_fd:
            try:
                fcntl.flock(self._lock_fd.fileno(), fcntl.LOCK_UN)
                self._lock_fd.close()
                if os.path.exists(self.lock_file_path):
                    os.remove(self.lock_file_path)
            except:
                pass
            self._lock_fd = None
        try:
            _sync_lock.release()
        except:
            pass
    
    def is_syncing(self) -> bool:
        if DataSyncService._is_syncing:
            return True
        if os.path.exists(self.lock_file_path):
            try:
                with open(self.lock_file_path, 'r') as f:
                    lock_info = json.load(f)
                    pid = lock_info.get("pid")
                    if pid:
                        try:
                            os.kill(pid, 0)
                            return True
                        except OSError:
                            pass
            except:
                pass
        return False
    
    def get_sync_status(self) -> dict:
        if self.is_syncing():
            start_time = DataSyncService._sync_start_time
            elapsed = (datetime.now() - start_time).total_seconds() if start_time else 0
            return {"is_syncing": True, "elapsed_seconds": int(elapsed)}
        return {"is_syncing": False, "elapsed_seconds": 0}
    
    def request_stop(self):
        self._stop_requested = True
    
    # ==================== å…ƒæ•°æ® ====================
    
    def get_metadata(self) -> dict:
        if os.path.exists(self.metadata_path):
            with open(self.metadata_path, 'r') as f:
                return json.load(f)
        return {"last_sync_date": None, "total_stocks": 0, "days": 0}
    
    def save_metadata(self, metadata: dict):
        with open(self.metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    # ==================== äº¤æ˜“æ—¥åŽ† ====================
    
    def get_trading_days(self, start_date: str, end_date: str) -> List[str]:
        """èŽ·å–äº¤æ˜“æ—¥åˆ—è¡¨"""
        try:
            df = self.pro.trade_cal(
                exchange='SSE',
                start_date=start_date,
                end_date=end_date,
                is_open='1'
            )
            return sorted(df['cal_date'].tolist())
        except Exception as e:
            print(f"èŽ·å–äº¤æ˜“æ—¥åŽ†å¤±è´¥: {e}")
            return []
    
    # ==================== æŒ‰æ—¥æœŸæ‰¹é‡èŽ·å– ====================
    
    def fetch_daily_by_date(self, trade_date: str) -> pd.DataFrame:
        """æŒ‰æ—¥æœŸèŽ·å–å…¨å¸‚åœºæ—¥çº¿è¡Œæƒ…"""
        try:
            df = self.pro.daily(trade_date=trade_date)
            if df is not None and not df.empty:
                df['ä»£ç '] = df['ts_code'].str[:6]
                df = df.rename(columns={
                    'trade_date': 'æ—¥æœŸ',
                    'open': 'å¼€ç›˜', 'high': 'æœ€é«˜', 'low': 'æœ€ä½Ž',
                    'close': 'æ”¶ç›˜', 'pre_close': 'æ˜¨æ”¶',
                    'change': 'æ¶¨è·Œé¢', 'pct_chg': 'æ¶¨è·Œå¹…',
                    'vol': 'æˆäº¤é‡', 'amount': 'æˆäº¤é¢'
                })
                df = df.drop(columns=['ts_code'], errors='ignore')
            return df
        except Exception as e:
            print(f"èŽ·å– {trade_date} daily å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def fetch_daily_basic_by_date(self, trade_date: str) -> pd.DataFrame:
        """æŒ‰æ—¥æœŸèŽ·å–å…¨å¸‚åœºæ¯æ—¥æŒ‡æ ‡"""
        try:
            df = self.pro.daily_basic(trade_date=trade_date)
            if df is not None and not df.empty:
                df['ä»£ç '] = df['ts_code'].str[:6]
                df = df.rename(columns={
                    'trade_date': 'æ—¥æœŸ',
                    'turnover_rate': 'æ¢æ‰‹çŽ‡',
                    'volume_ratio': 'é‡æ¯”',
                    'pe': 'PE', 'pe_ttm': 'PE_TTM', 'pb': 'PB',
                    'total_share': 'æ€»è‚¡æœ¬', 'float_share': 'æµé€šè‚¡æœ¬',
                    'total_mv': 'æ€»å¸‚å€¼', 'circ_mv': 'æµé€šå¸‚å€¼'
                })
                keep = ['ä»£ç ', 'æ—¥æœŸ', 'æ¢æ‰‹çŽ‡', 'é‡æ¯”', 'PE', 'PE_TTM', 'PB',
                       'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼', 'æ€»è‚¡æœ¬', 'æµé€šè‚¡æœ¬']
                available = [c for c in keep if c in df.columns]
                df = df[available]
            return df
        except Exception as e:
            print(f"èŽ·å– {trade_date} daily_basic å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def fetch_and_merge_by_date(self, trade_date: str) -> pd.DataFrame:
        """æŒ‰æ—¥æœŸèŽ·å–å¹¶åˆå¹¶ daily + daily_basic"""
        df_daily = self.fetch_daily_by_date(trade_date)
        if df_daily.empty:
            return pd.DataFrame()
        
        df_basic = self.fetch_daily_basic_by_date(trade_date)
        
        if not df_basic.empty:
            df = df_daily.merge(df_basic, on=['ä»£ç ', 'æ—¥æœŸ'], how='left')
        else:
            df = df_daily
        
        return df
    
    # ==================== SQLite å­˜å‚¨ ====================
    
    def save_to_database(self, df: pd.DataFrame) -> int:
        """
        å°†æ•°æ®ä¿å­˜åˆ° SQLiteï¼ˆä½¿ç”¨ REPLACE å®žçŽ° upsertï¼‰
        
        Returns:
            æ’å…¥/æ›´æ–°çš„è®°å½•æ•°
        """
        if df.empty:
            return 0
        
        # ç¡®ä¿åˆ—é¡ºåºå’Œæ•°æ®åº“ä¸€è‡´
        columns = ['æ—¥æœŸ', 'ä»£ç ', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½Ž', 'æ”¶ç›˜', 'æ˜¨æ”¶', 
                   'æ¶¨è·Œé¢', 'æ¶¨è·Œå¹…', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æ¢æ‰‹çŽ‡', 'é‡æ¯”',
                   'PE', 'PE_TTM', 'PB', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼', 'æ€»è‚¡æœ¬', 'æµé€šè‚¡æœ¬']
        
        # æ·»åŠ ç¼ºå¤±çš„åˆ—
        for col in columns:
            if col not in df.columns:
                df[col] = None
        
        df = df[columns]
        
        with sqlite3.connect(self.db_path) as conn:
            # ä½¿ç”¨ REPLACE INTO å®žçŽ° upsert
            placeholders = ', '.join(['?' for _ in columns])
            cols_str = ', '.join(columns)
            sql = f'REPLACE INTO daily_data ({cols_str}) VALUES ({placeholders})'
            
            # æ‰¹é‡æ’å…¥
            data = df.values.tolist()
            conn.executemany(sql, data)
            conn.commit()
            
            return len(data)
    
    def get_synced_dates(self) -> List[str]:
        """èŽ·å–å·²åŒæ­¥çš„æ—¥æœŸåˆ—è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('SELECT DISTINCT æ—¥æœŸ FROM daily_data ORDER BY æ—¥æœŸ')
            return [row[0] for row in cursor.fetchall()]
    
    def get_last_synced_date(self) -> Optional[str]:
        """èŽ·å–æœ€åŽåŒæ­¥çš„æ—¥æœŸ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('SELECT MAX(æ—¥æœŸ) FROM daily_data')
            result = cursor.fetchone()
            return result[0] if result else None
    
    def get_stock_count(self) -> int:
        """èŽ·å–è‚¡ç¥¨æ•°é‡"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('SELECT COUNT(DISTINCT ä»£ç ) FROM daily_data')
            return cursor.fetchone()[0]
    
    def get_record_count(self) -> int:
        """èŽ·å–æ€»è®°å½•æ•°"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('SELECT COUNT(*) FROM daily_data')
            return cursor.fetchone()[0]
    
    # ==================== ä¸»åŒæ­¥é€»è¾‘ ====================
    
    def sync_all_stocks(
        self, 
        days: int = 120, 
        progress_callback=None,
        force: bool = False
    ) -> bool:
        """
        åŒæ­¥å…¨å¸‚åœºåŽ†å²æ•°æ®ï¼ˆSQLite å­˜å‚¨ï¼‰
        
        ç­–ç•¥ï¼š
        1. æŒ‰æ—¥æœŸèŽ·å–å…¨å¸‚åœºæ•°æ®
        2. åˆå¹¶ daily + daily_basic
        3. æ‰¹é‡å†™å…¥ SQLiteï¼ˆä½¿ç”¨äº‹åŠ¡ï¼‰
        """
        if not self._acquire_lock():
            print("âš ï¸ å¦ä¸€ä¸ªåŒæ­¥ä»»åŠ¡æ­£åœ¨è¿è¡Œ")
            if progress_callback:
                progress_callback(0, 0, "å·²æœ‰ä»»åŠ¡è¿è¡Œ", "")
            return False
        
        try:
            print(f"ðŸš€ å¼€å§‹åŒæ­¥ {days} å¤©æ•°æ®ï¼ˆSQLite å­˜å‚¨æ¨¡å¼ï¼‰...")
            
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            today = datetime.now()
            end_date = (today - timedelta(days=1)).strftime("%Y%m%d")
            start_date = (today - timedelta(days=days)).strftime("%Y%m%d")
            
            # èŽ·å–äº¤æ˜“æ—¥åˆ—è¡¨
            trading_days = self.get_trading_days(start_date, end_date)
            if not trading_days:
                print("âŒ èŽ·å–äº¤æ˜“æ—¥åŽ†å¤±è´¥")
                return False
            
            print(f"ðŸ“… äº¤æ˜“æ—¥èŒƒå›´: {trading_days[0]} ~ {trading_days[-1]}ï¼Œå…± {len(trading_days)} ä¸ªäº¤æ˜“æ—¥")
            
            # å¢žé‡æ¨¡å¼
            if not force:
                last_synced = self.get_last_synced_date()
                if last_synced:
                    trading_days = [d for d in trading_days if d > last_synced]
                    if not trading_days:
                        print("âœ… æ•°æ®å·²æ˜¯æœ€æ–°")
                        return True
                    print(f"ðŸ“Š å¢žé‡åŒæ­¥: {len(trading_days)} ä¸ªæ–°äº¤æ˜“æ—¥")
            else:
                print("âš ï¸ å¼ºåˆ¶åŒæ­¥æ¨¡å¼ï¼Œæ¸…ç©ºæ•°æ®åº“...")
                with sqlite3.connect(self.db_path) as conn:
                    conn.execute('DELETE FROM daily_data')
                    conn.commit()
            
            # åŒæ­¥
            total_records = 0
            self._stop_requested = False
            
            for i, trade_date in enumerate(trading_days):
                if self._stop_requested:
                    print("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·")
                    break
                
                # èŽ·å–æ•°æ®
                df = self.fetch_and_merge_by_date(trade_date)
                
                if not df.empty:
                    # ä¿å­˜åˆ° SQLite
                    count = self.save_to_database(df)
                    total_records += count
                    status = f"èŽ·å– {len(df)} æ¡ï¼Œç´¯è®¡ {total_records} æ¡"
                else:
                    status = "æ— æ•°æ®"
                
                if progress_callback:
                    progress_callback(i + 1, len(trading_days), trade_date, status)
                
                # çŸ­æš‚é—´éš”
                time.sleep(0.15)
            
            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "last_sync_date": datetime.now().isoformat(),
                "total_stocks": self.get_stock_count(),
                "total_records": self.get_record_count(),
                "days": days,
                "date_range": {
                    "start": trading_days[0] if trading_days else start_date,
                    "end": trading_days[-1] if trading_days else end_date
                },
                "storage": "sqlite",
                "db_file": self.db_path
            }
            self.save_metadata(metadata)
            
            print(f"âœ… åŒæ­¥å®Œæˆ: {len(trading_days)} ä¸ªäº¤æ˜“æ—¥, {self.get_stock_count()} åªè‚¡ç¥¨, {total_records} æ¡è®°å½•")
            return True
        
        finally:
            self._release_lock()
    
    # ==================== æ•°æ®æŸ¥è¯¢ ====================
    
    def get_stock_history(self, code: str, days: int = None) -> pd.DataFrame:
        """èŽ·å–å•åªè‚¡ç¥¨åŽ†å²æ•°æ®"""
        sql = 'SELECT * FROM daily_data WHERE ä»£ç  = ? ORDER BY æ—¥æœŸ'
        params = [code]
        
        if days:
            sql = 'SELECT * FROM daily_data WHERE ä»£ç  = ? ORDER BY æ—¥æœŸ DESC LIMIT ?'
            params = [code, days]
        
        with sqlite3.connect(self.db_path) as conn:
            df = pd.read_sql_query(sql, conn, params=params)
        
        if days:
            df = df.sort_values('æ—¥æœŸ')
        
        return df
    
    def get_daily_data(self, trade_date: str) -> pd.DataFrame:
        """èŽ·å–æŸä¸€å¤©çš„å…¨å¸‚åœºæ•°æ®"""
        sql = 'SELECT * FROM daily_data WHERE æ—¥æœŸ = ?'
        with sqlite3.connect(self.db_path) as conn:
            return pd.read_sql_query(sql, conn, params=[trade_date])
    
    def query(self, sql: str, params: tuple = None) -> pd.DataFrame:
        """æ‰§è¡Œè‡ªå®šä¹‰ SQL æŸ¥è¯¢"""
        with sqlite3.connect(self.db_path) as conn:
            return pd.read_sql_query(sql, conn, params=params)
    
    def get_stocks_by_filter(
        self,
        trade_date: str = None,
        min_pct_chg: float = None,
        max_pct_chg: float = None,
        min_pe: float = None,
        max_pe: float = None,
        min_pb: float = None,
        max_pb: float = None,
        max_market_cap: float = None,  # äº¿
        min_turnover: float = None,
        limit: int = 100
    ) -> pd.DataFrame:
        """
        æŒ‰æ¡ä»¶ç­›é€‰è‚¡ç¥¨
        
        ç¤ºä¾‹ï¼š
            # èŽ·å–æ¶¨åœè‚¡
            get_stocks_by_filter(trade_date='20260130', min_pct_chg=9.5)
            
            # èŽ·å–ä½Ž PE å°ç›˜è‚¡
            get_stocks_by_filter(max_pe=20, max_market_cap=50)
        """
        conditions = []
        params = []
        
        if trade_date:
            conditions.append('æ—¥æœŸ = ?')
            params.append(trade_date)
        
        if min_pct_chg is not None:
            conditions.append('æ¶¨è·Œå¹… >= ?')
            params.append(min_pct_chg)
        
        if max_pct_chg is not None:
            conditions.append('æ¶¨è·Œå¹… <= ?')
            params.append(max_pct_chg)
        
        if min_pe is not None:
            conditions.append('PE >= ?')
            params.append(min_pe)
        
        if max_pe is not None:
            conditions.append('PE <= ?')
            params.append(max_pe)
        
        if min_pb is not None:
            conditions.append('PB >= ?')
            params.append(min_pb)
        
        if max_pb is not None:
            conditions.append('PB <= ?')
            params.append(max_pb)
        
        if max_market_cap is not None:
            conditions.append('æµé€šå¸‚å€¼ <= ?')
            params.append(max_market_cap * 1e4)  # äº¿ -> ä¸‡
        
        if min_turnover is not None:
            conditions.append('æ¢æ‰‹çŽ‡ >= ?')
            params.append(min_turnover)
        
        where_clause = ' AND '.join(conditions) if conditions else '1=1'
        sql = f'''
            SELECT * FROM daily_data 
            WHERE {where_clause}
            ORDER BY æ—¥æœŸ DESC, æ¶¨è·Œå¹… DESC
            LIMIT ?
        '''
        params.append(limit)
        
        with sqlite3.connect(self.db_path) as conn:
            return pd.read_sql_query(sql, conn, params=params)
    
    def get_zt_stocks(self, trade_date: str) -> pd.DataFrame:
        """èŽ·å–æ¶¨åœè‚¡ï¼ˆæ¶¨å¹… >= 9.5%ï¼‰"""
        return self.get_stocks_by_filter(trade_date=trade_date, min_pct_chg=9.5, limit=500)
    
    def get_sync_status_info(self) -> dict:
        """èŽ·å–åŒæ­¥çŠ¶æ€ä¿¡æ¯"""
        metadata = self.get_metadata()
        
        db_size = 0
        if os.path.exists(self.db_path):
            db_size = os.path.getsize(self.db_path) / 1024 / 1024
        
        return {
            "last_sync": metadata.get("last_sync_date"),
            "total_stocks": self.get_stock_count(),
            "total_records": self.get_record_count(),
            "days": metadata.get("days", 0),
            "date_range": metadata.get("date_range", {}),
            "db_size_mb": round(db_size, 2),
            "storage": "sqlite",
            "db_file": self.db_path
        }


# å‘½ä»¤è¡Œå…¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Aè‚¡æ•°æ®åŒæ­¥å·¥å…·ï¼ˆSQLite å­˜å‚¨ï¼‰")
    parser.add_argument("--days", type=int, default=120, help="åŒæ­¥å¤©æ•°")
    parser.add_argument("--status", action="store_true", help="æŸ¥çœ‹çŠ¶æ€")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶å…¨é‡åŒæ­¥")
    parser.add_argument("--query", type=str, help="æ‰§è¡Œ SQL æŸ¥è¯¢")
    
    args = parser.parse_args()
    sync = DataSyncService()
    
    if args.status:
        status = sync.get_sync_status_info()
        print("ðŸ“Š åŒæ­¥çŠ¶æ€:")
        print(f"  æ•°æ®åº“: {status['db_file']}")
        print(f"  å¤§å°: {status['db_size_mb']} MB")
        print(f"  è‚¡ç¥¨æ•°é‡: {status['total_stocks']}")
        print(f"  è®°å½•æ€»æ•°: {status['total_records']}")
        print(f"  æ—¥æœŸèŒƒå›´: {status['date_range']}")
        print(f"  æœ€åŽåŒæ­¥: {status['last_sync']}")
    elif args.query:
        print(f"æ‰§è¡ŒæŸ¥è¯¢: {args.query}")
        df = sync.query(args.query)
        print(df.to_string())
    else:
        def progress(current, total, date, status):
            pct = current / total * 100 if total > 0 else 0
            print(f"[{current}/{total}] {pct:.0f}% | {date} | {status}")
        
        sync.sync_all_stocks(days=args.days, progress_callback=progress, force=args.force)
